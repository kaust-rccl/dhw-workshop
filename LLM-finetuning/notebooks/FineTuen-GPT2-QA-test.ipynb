{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba68f878-c298-4ba5-82d2-61f2956f2ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForQuestionAnswering,GPT2LMHeadModel,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cbfed2-e5a6-43c4-b699-1e9b65c30613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "b4f65936-1431-4d8a-aeb8-a63a4668e15c",
   "metadata": {
    "tags": []
   },
   "source": [
    "df = pd.read_csv('./qna_data.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "959351ca-4c03-43c1-85b7-7e19dbad26d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#df = df.drop('qtype', axis=1)\n",
    "df = df.rename(columns={'Question': 'question', 'Answer': 'answer'})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39897053-6bff-4925-a8d1-c6312e1ba981",
   "metadata": {
    "tags": []
   },
   "source": [
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b524a26b-01ae-48b4-b9fc-7e882ee688c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"team-bay/data-science-qa\",split=['train'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ea834f-c4f9-4c37-a1d6-f91826035020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset=dataset.remove_columns(['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d6a79be-431f-481e-85ba-3ea9a078288c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_train_dataset=dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1ef082f-5d3a-458d-b6fe-6d1ceec2cc4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset=full_train_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dfb9e55-e53f-4bdc-833e-b770a58b7457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset=full_train_dataset['train'].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bbc6380-5b12-44ea-911f-64596be6f5cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dataset=train_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45c0cda2-886e-4a06-90be-a5032e7baca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 76\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.pop('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "567b505f-ba4d-4fbe-aacc-6bd8b3088dc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset=train_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "316379c2-5a60-49ab-8fae-d3aa51ea94d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 95\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f212a2-1629-4301-9cc2-cdf1c8355607",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 76\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5a81be2-7481-4a8f-bc4d-ada48df41580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "health_dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb7dfad3-db3a-4bd6-a66e-59f422ac94ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'gpt2'\n",
    "model = GPT2LMHeadModel.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f72dfeb-83b7-4ac8-a607-ad8beccb4a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [q + \" [SEP] \" + a for q, a in zip(examples[\"question\"], examples[\"answer\"])]\n",
    "   # The \"inputs\" are the tokenized answer:\n",
    "#    inputs = [doc for doc in examples[\"question\"] + \" [SEP] \" + doc for doc in examples[\"answer\"]]\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, max_length=200, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "  \n",
    "   # The \"labels\" are the tokenized outputs:\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a69cde33-80a0-4593-b939-33c30190a273",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396f72e6c72046d79e1594e457148da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/302 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5311548c44744755ad8f023d8353ab5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/76 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883573e59b894339936ce243730e321b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/95 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = health_dataset_dict.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67ddb7fa-8b62-4a91-9202-e37d3b235aa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 302\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'answer', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 76\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 95\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e706e29e-50aa-4ed4-a777-5df9ad77a17f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global Parameters\n",
    "L_RATE = 3e-4\n",
    "BATCH_SIZE = 8\n",
    "PER_DEVICE_EVAL_BATCH = 8\n",
    "WEIGHT_DECAY = 0.01\n",
    "SAVE_TOTAL_LIM = 3\n",
    "NUM_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aad0653d-2fc0-424e-83d5-6919965fe6d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ibex/ai/home/shaima0d/KSL_Trainings/rts-tutorials/install/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "   output_dir=\"./results\",\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   learning_rate=L_RATE,\n",
    "   report_to=None,\n",
    "   logging_steps=10,\n",
    "   per_device_train_batch_size=BATCH_SIZE,\n",
    "   per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n",
    "   weight_decay=WEIGHT_DECAY,\n",
    "   save_total_limit=SAVE_TOTAL_LIM,\n",
    "   num_train_epochs=NUM_EPOCHS,\n",
    "   push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e08d647d-6c56-4d9c-8aa4-751f433db36a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-22 23:04:27,553] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3741196/3747980684.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The default cache directory for DeepSpeed Triton autotune, /home/shaima0d/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ibex/ai/home/shaima0d/KSL_Trainings/rts-tutorials/install/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/ibex/ai/home/shaima0d/KSL_Trainings/rts-tutorials/install/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, input, weight, bias=None):\n",
      "/ibex/ai/home/shaima0d/KSL_Trainings/rts-tutorials/install/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    data_collator= DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce86ec5f-fde4-4c97-b1ab-66acf8edad08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 00:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.581800</td>\n",
       "      <td>2.224871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.631200</td>\n",
       "      <td>2.116260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.108000</td>\n",
       "      <td>2.175313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=114, training_loss=1.8529781165875887, metrics={'train_runtime': 11.8675, 'train_samples_per_second': 76.343, 'train_steps_per_second': 9.606, 'total_flos': 45311712768000.0, 'train_loss': 1.8529781165875887, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d06a4f93-95d8-4bcd-9c49-f3e31af7ccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e445d081-6c90-4ac6-959a-2b745c5934d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_tokenizer(tokenizer_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0237c461-7975-46f9-878a-ff8d1e35de6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(model_path, sequence, max_length):\n",
    "    \n",
    "    model = load_model(model_path)\n",
    "    tokenizer = load_tokenizer(model_path)\n",
    "    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n",
    "    final_outputs = model.generate(\n",
    "        ids,\n",
    "        do_sample=True,\n",
    "        max_length=max_length,\n",
    "        pad_token_id=model.config.eos_token_id,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "    )\n",
    "    print(tokenizer.decode(final_outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8049c0c6-32a6-4e4f-9368-71dd6379301a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q] How do I do reinforcement learning? [SEP] reinforcement learning is a machine learning paradigm where an agent learns to make decisions based on actions made by other agents in the environment, often leveraging pretext actions or pretext tasks to learn useful representations without explicit training. The goal of reinforcement learning is to maximize cumulative rewards and minimize cumulative losses, enabling agents to make better decisions by interacting with each other more often. Expectation-based models are an example of reinforcement learning where an agent learns to maximize cumulative rewards while evaluating actions across multiple scenarios. Expectation-based models are applications such as gaming and social media analytics, where an agent must decide which objective to focus on to maximize cumulative rewards. Expectation-based models are examples of objective-based\n"
     ]
    }
   ],
   "source": [
    "model2_path = \"./results/checkpoint-114/\"\n",
    "sequence2 = \"[Q] How do I do reinforcement learning?\"\n",
    "max_len = 150\n",
    "generate_text(model2_path, sequence2, max_len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f916f193-ffd8-4c8c-88eb-b2ecff280510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generate = pipeline(\"text-generation\", model=\"openai-community/gpt2\",\n",
    "                    clean_up_tokenization_spaces=True,\n",
    "                    device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "420a0265-e14b-4b70-92c2-42704f4230b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '[Q] How do I do reinforcement learning? What you learn that makes it better, and how do you improve it? How are you going to'},\n",
       " {'generated_text': '[Q] How do I do reinforcement learning?[/Q] [A] [B]How do I do all of this?[/B]'},\n",
       " {'generated_text': \"[Q] How do I do reinforcement learning?[/q]\\n\\nIf I'm interested in training a character for different characters, I go through\"}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "generate(\"[Q] How do I do reinforcement learning?\", max_length=30, num_return_sequences=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcc3a9e-21c2-4f8a-ad22-462031c9ecd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
