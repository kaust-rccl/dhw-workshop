{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba68f878-c298-4ba5-82d2-61f2956f2ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForQuestionAnswering,GPT2LMHeadModel,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b524a26b-01ae-48b4-b9fc-7e882ee688c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"pierre-pessarossi/climate-question-answers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4acec90-eb9f-4f17-a1dc-b5fd6199841b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generate = pipeline(\"text-generation\", model=\"openai-community/gpt2\",\n",
    "                    clean_up_tokenization_spaces=True,\n",
    "                    device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e06650ef-cc6b-4a83-904b-edc1e811d52c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '[Q] What is environmental goveranace? What is climate goveranace? Environmental goveranace, e.g., human activities, the industrial activity (excess oil and gas for example), is a term that may be relevant to environmental goveranace of the human body. It is understood that there may be a relationship between the various environmental factors, such as the amount of waste at the disposal site, the amount of nutrients in the waste, and the frequency of'},\n",
       " {'generated_text': '[Q] What is environmental goveranace? (Source: J.H.G. Schmitz, Die eutlich Deutscher Abhandlung von deutschen Volkswirtschafts des Migrants, in: E.F. Schmitz, ed., Die eutlich Deutscher Abhandlung von Deutscher, Deutscher, and the Deutschland, 1770-1811 (New York:'},\n",
       " {'generated_text': '[Q] What is environmental goveranace?[/q]\\n\\n\"Well, it\\'s probably one of the first steps in your environmental studies,\" says Soderstrom. And for the most part she\\'s done it for the good of an organization that she wants the organization to help. She says that it\\'s an act of courage, and that the organization is doing what it has to do.\\n\\n\"I am now able to move on,\" she says. \"That helps me'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "generate(\"[Q] What is environmental goveranace?\", max_length=100, num_return_sequences=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ea834f-c4f9-4c37-a1d6-f91826035020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset=dataset.rename_column(\"instruction\", \"question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ef082f-5d3a-458d-b6fe-6d1ceec2cc4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset=dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dfb9e55-e53f-4bdc-833e-b770a58b7457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset=dataset['train'].train_test_split(test_size=0.2,keep_in_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bbc6380-5b12-44ea-911f-64596be6f5cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dataset=train_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45c0cda2-886e-4a06-90be-a5032e7baca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 1407\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.pop('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "567b505f-ba4d-4fbe-aacc-6bd8b3088dc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset=train_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbe402c9-8c95-49df-9531-cd1e06db36e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 5626\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "316379c2-5a60-49ab-8fae-d3aa51ea94d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 1758\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87f212a2-1629-4301-9cc2-cdf1c8355607",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 1407\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5a81be2-7481-4a8f-bc4d-ada48df41580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "climate_dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb7dfad3-db3a-4bd6-a66e-59f422ac94ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'gpt2'\n",
    "model = GPT2LMHeadModel.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f72dfeb-83b7-4ac8-a607-ad8beccb4a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    \n",
    "    # To catch any anomaly in the curation of dataset i.e. bad datatype either in question or an answer, \n",
    "    # we set the string to a NULL token.\n",
    "    batch_size=len(examples['question'])\n",
    "    for i in range(batch_size):\n",
    "        if examples['question'][i] == None:\n",
    "            examples['question'][i] = \"[NULL]\"\n",
    "        if examples['answer'][i] == None:\n",
    "            examples['answer'][i] = \"[NULL]\"\n",
    "\n",
    "    inputs = [q + \" [SEP] \" + a for q, a in zip(examples[\"question\"], examples[\"answer\"])]\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, max_length=200, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "  \n",
    "   # The \"labels\" are the tokenized outputs:\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a69cde33-80a0-4593-b939-33c30190a273",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18cc54799a834a81ad8ec44b0ee5bb24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5624 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c52dedc1dd401fb6a81a5f44fd5a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1404 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2ce9fd39e9413ab53ff9edb0f76114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1756 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.58 s, sys: 770 ms, total: 6.35 s\n",
      "Wall time: 4.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_dataset = climate_dataset_dict.map(\n",
    "    preprocess_function, \n",
    "    batched=True,\n",
    "batch_size=4,drop_last_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e706e29e-50aa-4ed4-a777-5df9ad77a17f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global Parameters\n",
    "L_RATE = 3e-4\n",
    "BATCH_SIZE = 64\n",
    "PER_DEVICE_EVAL_BATCH = 8\n",
    "WEIGHT_DECAY = 0.01\n",
    "SAVE_TOTAL_LIM = 3\n",
    "NUM_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aad0653d-2fc0-424e-83d5-6919965fe6d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ibex/ai/home/shaima0d/KSL_Trainings/rts-tutorials/install/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "   output_dir=\"./results\",\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   learning_rate=L_RATE,\n",
    "   report_to=None,\n",
    "   logging_steps=10,\n",
    "   per_device_train_batch_size=BATCH_SIZE,\n",
    "   per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n",
    "   weight_decay=WEIGHT_DECAY,\n",
    "   save_total_limit=SAVE_TOTAL_LIM,\n",
    "   num_train_epochs=NUM_EPOCHS,\n",
    "   push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e08d647d-6c56-4d9c-8aa4-751f433db36a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2224357/3747980684.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    data_collator= DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce86ec5f-fde4-4c97-b1ab-66acf8edad08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4c4b3ff-f971-4da8-b0b9-d7f260f8010f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='88' max='88' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [88/88 01:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.916700</td>\n",
       "      <td>2.664665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 28s, sys: 957 ms, total: 1min 29s\n",
      "Wall time: 1min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=88, training_loss=1.8227688399228184, metrics={'train_runtime': 90.3598, 'train_samples_per_second': 62.24, 'train_steps_per_second': 0.974, 'total_flos': 549203189760000.0, 'train_loss': 1.8227688399228184, 'epoch': 1.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d06a4f93-95d8-4bcd-9c49-f3e31af7ccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e445d081-6c90-4ac6-959a-2b745c5934d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_tokenizer(tokenizer_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0237c461-7975-46f9-878a-ff8d1e35de6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(model_path, sequence, max_length):\n",
    "    \n",
    "    model = load_model(model_path)\n",
    "    tokenizer = load_tokenizer(model_path)\n",
    "    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n",
    "    final_outputs = model.generate(\n",
    "        ids,\n",
    "        do_sample=True,\n",
    "        max_length=max_length,\n",
    "        pad_token_id=model.config.eos_token_id,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "    )\n",
    "    print(tokenizer.decode(final_outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8049c0c6-32a6-4e4f-9368-71dd6379301a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q] What is environmental goveranace? [SEP] Environmental goveranace, also known as green goverment, is a Dutch law that prevents private property from being used as a disguise for commercial purposes. This law specifically prohibited the use of chemical fertilizers, prohibiting the planting and transport of trees as a disguise for commercial purposes, and required the planting of certain crops to disguise their intended environmental effects. Critics of green goveranace argue that the law has been used to circumvent environmental issues and interfere with the private property rights of farmers and multinational corporations. However, environmental NGOs argue that the statute has been used to allow the planting and transportation of food, shelter and other resources without permission. In September 2022, the Dutch government granted permission to establish a green goveranace in Durban, with the goal of creating a 'green goverment', which would have an impact on Dutch natural resources and biodiversity. The Dutch government has also enacted a law to prohibit the use of cyanobacteria in agriculture, set legal limits on the use of fossil fuels, and established a climate change Commission. However, environmental groups have criticized the proposed green goveranace as a 'political tool' for the Dutch political right-wing Dutch public. Critics of green goveranace argue that the proposed green goverment would cause more damage to ecosystems than the direct planting and transportation of fossil fuels. In February 2023, the Dutch Green Party (Green Party) and the\n"
     ]
    }
   ],
   "source": [
    "model2_path = \"./results/checkpoint-1200/\"\n",
    "sequence2 = \"[Q] What is environmental goveranace?\"\n",
    "max_len = 300\n",
    "generate_text(model2_path, sequence2, max_len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e838ee72-6fd4-42ec-8c7c-f388256b578d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
